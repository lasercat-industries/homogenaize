{"version":3,"file":"index.js","sourceRoot":"","sources":["../src/index.ts"],"names":[],"mappings":"AAAA,sBAAsB;AACtB,OAAO,EACL,SAAS,EACT,eAAe,EACf,kBAAkB,EAClB,eAAe,GAWhB,MAAM,UAAU,CAAC;AAgClB,qBAAqB;AACrB,OAAO,EAAE,gBAAgB,EAAE,mBAAmB,EAAE,gBAAgB,EAAE,MAAM,mBAAmB,CAAC;AAE5F,gCAAgC;AAChC,OAAO,EAAE,CAAC,EAAE,MAAM,KAAK,CAAC;AAUxB,OAAO,EAAE,aAAa,EAAE,gBAAgB,EAAE,aAAa,EAAE,MAAM,yBAAyB,CAAC","sourcesContent":["// Main client exports\nexport {\n  createLLM,\n  createOpenAILLM,\n  createAnthropicLLM,\n  createGeminiLLM,\n  type LLMClient,\n  type LLMConfig,\n  type ToolConfig,\n  type ExecutableTool,\n  type ToolResult,\n  type BaseChatOptions,\n  type ChatOptions,\n  type StreamOptions,\n  type DefineToolOptions,\n  type ExecuteToolsOptions,\n} from './client';\n\n// Provider exports\nexport type {\n  Provider,\n  Message,\n  MessageRole,\n  TextContent,\n  MultiModalContent,\n  Tool,\n  ToolCall,\n  ChatRequest,\n  ChatResponse,\n  StreamingResponse,\n  Usage,\n  ProviderCapabilities,\n} from './providers/provider';\n\n// Provider type exports\nexport type {\n  ProviderName,\n  ProviderChatRequest,\n  ProviderChatResponse,\n  OpenAIChatRequest,\n  AnthropicChatRequest,\n  GeminiChatRequest,\n  OpenAIChatResponse,\n  AnthropicChatResponse,\n  GeminiChatResponse,\n  TypedProvider,\n} from './providers/types';\n\n// Type guard exports\nexport { isOpenAIResponse, isAnthropicResponse, isGeminiResponse } from './providers/types';\n\n// Re-export zod for convenience\nexport { z } from 'zod';\n\n// Model type exports\nexport type {\n  OpenaiModel,\n  AnthropicModel,\n  GeminiModel,\n  AllProviderModels,\n} from './generated/model-types';\n\nexport { OPENAI_MODELS, ANTHROPIC_MODELS, GEMINI_MODELS } from './generated/model-types';\n"]}